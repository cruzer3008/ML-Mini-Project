{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/fer2013.csv\") as file:\n",
    "    content_of_file = file.readlines()\n",
    " \n",
    "content_array = np.array(content_of_file) \n",
    "numof_instances = content_array.size\n",
    "print(\"number of instances: \",numof_instances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numClasses = 7 #angry, disgust, fear, happy, sad, surprise, neutral\n",
    "batchSize = 256\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    " \n",
    "for i in range(1,numof_instances):  \n",
    "    emotion, img, usage = content_array[i].split(\",\")\n",
    "\n",
    "    val = img.split(\" \")\n",
    "    pixels = np.array(val, 'float32')\n",
    "\n",
    "    emotion = keras.utils.to_categorical(emotion, numClasses)\n",
    "\n",
    "    if 'Training' in usage:\n",
    "        y_train.append(emotion)\n",
    "        x_train.append(pixels)\n",
    "    elif 'PublicTest' in usage:\n",
    "        y_test.append(emotion)\n",
    "        x_test.append(pixels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train, 'float32')\n",
    "\n",
    "y_train = np.array(y_train, 'float32')\n",
    "x_test = np.array(x_test, 'float32')\n",
    "y_test = np.array(y_test, 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 48, 48, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 48, 48, 1)\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape[0], 'train data')\n",
    "print(x_test.shape[0], 'test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct CNN structure\n",
    "model = Sequential()\n",
    "\n",
    "#1st convolution layer\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(numClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch process\n",
    "gen = ImageDataGenerator()\n",
    "trainGenerator = gen.flow(x_train, y_train, batch_size=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy'\n",
    "    , optimizer=keras.optimizers.Adam()\n",
    "    , metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(trainGenerator, steps_per_epoch=batchSize, epochs=epochs) #train for randomly selected one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function for drawing bar chart for emotion preditions\n",
    "def emotionAnalysis(emotions):\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    \n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitorTestsetResults = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if monitorTestsetResults == True:\n",
    "    #make predictions for test set\n",
    "    predictions = model.predict(x_test)\n",
    "\n",
    "    index = 0\n",
    "    for i in predictions:\n",
    "        if index < 30 and index >= 20:\n",
    "            #print(i) #predicted scores\n",
    "            #print(y_test[index]) #actual scores\n",
    "\n",
    "            testing_img = np.array(x_test[index], 'float32')\n",
    "            testing_img = testing_img.reshape([48, 48]);\n",
    "\n",
    "            plt.gray()\n",
    "            plt.imshow(testing_img)\n",
    "            plt.show()\n",
    "\n",
    "            print(i)\n",
    "\n",
    "            emotion_analysis(i)\n",
    "            print(\"----------------------------------------------\")\n",
    "        index = index + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make prediction for custom image out of test set\n",
    "img = image.load_img(\"./data/a.jpg\", grayscale=True, target_size=(48, 48))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "\n",
    "x /= 255\n",
    "\n",
    "custom = model.predict(x)\n",
    "emotion_analysis(custom[0])\n",
    "\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real time emotion detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opencv initialization\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "#face expression recognizer initialization\n",
    "from keras.models import model_from_json\n",
    "dl_model = model_from_json(open(\"model.json\", \"r\").read())\n",
    "dl_model.load_weights('model.h5') #load weights\n",
    "\n",
    "emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "\n",
    "while(True):\n",
    "    ret, img = capture.read()\n",
    "    #img = cv2.imread('C:/Users/IS96273/Desktop/hababam.jpg')\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    #print(faces) #locations of detected faces\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) #draw rectangle to main image\n",
    "\n",
    "        detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "        detected_face = cv2.cvtColor(detected_face, cv2.COLOR_BGR2GRAY) #transform to gray scale\n",
    "        detected_face = cv2.resize(detected_face, (48, 48)) #resize to 48x48\n",
    "\n",
    "        img_pixels = image.img_to_array(detected_face)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\n",
    "        img_pixels /= 255 #pixels are in scale of [0, 255]. normalize all pixels in scale of [0, 1]\n",
    "\n",
    "        predictions = dl_model.predict(img_pixels) #store probabilities of 7 expressions\n",
    "\n",
    "        #find max indexed array 0: angry, 1:disgust, 2:fear, 3:happy, 4:sad, 5:surprise, 6:neutral\n",
    "        max_index = np.argmax(predictions[0])\n",
    "\n",
    "        emotion = emotions[max_index]\n",
    "        \n",
    "        #write emotion text above rectangle\n",
    "        cv2.putText(img, emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    cv2.imshow('img',img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #press q to quit\n",
    "        break\n",
    "\n",
    "#kill open cv things\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
